# Task 14: Machine Learning

This task focuses on implementing and evaluating machine learning models using the Titanic dataset. It covers logistic regression and decision trees with an emphasis on cross-validation, performance metrics, and analyzing overfitting and underfitting.

## Table of Contents
- [Dataset](#dataset)
- [Tasks](#tasks)
  - [Evaluating Logistic Regression with Cross-Validation](#evaluating-logistic-regression-with-cross-validation)
  - [Analyzing Overfitting and Underfitting in Decision Trees](#analyzing-overfitting-and-underfitting-in-decision-trees)
  - [Calculating Precision, Recall, and F1-Score for Logistic Regression](#calculating-precision-recall-and-f1-score-for-logistic-regression)
  - [ROC Curve Analysis for Decision Trees](#roc-curve-analysis-for-decision-trees)
  - [Comparing Model Performance with and without Cross-Validation](#comparing-model-performance-with-and-without-cross-validation)
- [Results and Analysis](#results-and-analysis)
- [Conclusion](#conclusion)
- [Repository Structure](#repository-structure)
- [References](#references)

## Dataset
The Titanic dataset is used for this task. You can download it from [Kaggle](https://www.kaggle.com/datasets/yasserh/titanic-dataset).

## Tasks

### Evaluating Logistic Regression with Cross-Validation
- **Objective:** Implement logistic regression and evaluate the model using k-fold cross-validation.
- **Steps:**
  1. Load and preprocess the data.
  2. Implement logistic regression.
  3. Evaluate the model using k-fold cross-validation.
  4. Compare cross-validation scores with a single train-test split evaluation.

### Analyzing Overfitting and Underfitting in Decision Trees
- **Objective:** Train a decision tree classifier with varying depths to analyze overfitting and underfitting.
- **Steps:**
  1. Train decision trees with different depths.
  2. Plot training and validation accuracies to visualize the effects.

### Calculating Precision, Recall, and F1-Score for Logistic Regression
- **Objective:** Implement logistic regression and calculate precision, recall, and F1-score for the model.
- **Steps:**
  1. Implement logistic regression.
  2. Calculate precision, recall, and F1-score.
  3. Discuss how these metrics provide insights into model performance in your week article.

### ROC Curve Analysis for Decision Trees
- **Objective:** Implement a decision tree classifier and plot the ROC curve.
- **Steps:**
  1. Implement a decision tree classifier.
  2. Plot the ROC curve.
  3. Compute the AUC (Area Under the Curve) and interpret the results.

### Comparing Model Performance with and without Cross-Validation
- **Objective:** Train logistic regression and decision tree models with and without cross-validation. Compare their performance metrics, including accuracy, precision, and recall.
- **Steps:**
  1. Train logistic regression and decision tree models with cross-validation.
  2. Train logistic regression and decision tree models without cross-validation.
  3. Compare performance metrics.

## Results and Analysis
- **Logistic Regression with Cross-Validation:** [Include results and analysis]
- **Decision Trees Overfitting and Underfitting Analysis:** [Include results and analysis]
- **Precision, Recall, and F1-Score for Logistic Regression:** [Include results and analysis]
- **ROC Curve Analysis for Decision Trees:** [Include results and analysis]
- **Model Performance Comparison:** [Include results and analysis]

